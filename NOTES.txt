My GPU: NVIDIA RTX A4000
Python: 3.8.13

Install system packages:

    sudo apt update
    sudo apt install python3-pip

Install PyTorch:

    pip install torch==1.7.1+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html

Init modules:

    git submodule update --init; cd tacotron2; git submodule update --init

Using dataset:

    URL: https://github.com/egorsmkv/ukrainian-tts-datasets/tree/main/lada
    Archive: dataset_lada_trimmed_22khz.zip

    wget https://huggingface.co/datasets/Yehor/ukrainian-tts-lada/resolve/main/dataset_lada_trimmed_22khz.zip
    unzip dataset_lada_trimmed_22khz.zip

Install Ukrainian G2P:

    pip install -U git+https://github.com/egorsmkv/ukro_g2p

Install dependencies:

    pip install -r requirements.txt

Fix error "ModuleNotFoundError: No module named 'numba.decorators'" by :

    pip install numba==0.48

Fix error "TypeError: guvectorize() missing 1 required positional argument: 'signature'" by :

    pip install resampy==0.3.1

Export MELs (optional, just to check that all works well):

    python3 data.py -c config.json -f filelists/lada_ukrainian_train_filelist.txt -o outdir_train_mels

====

TRAIN

1) Run training in the background (1st stage)

    nohup python3 train.py -c config.json -p train_config.output_directory=outdir data_config.use_attn_prior=1 > training_1st_stage.out 2>&1 &

1.2) Run training in the background (2nd stage)

    nohup python3 train.py -c config.json -p train_config.output_directory=outdir data_config.use_attn_prior=0 train_config.checkpoint_path=model_niters > training_2nd_stage.out 2>&1 &

2) Run the tesorboard:

    tensorboard --logdir outdir/logs

or 

    nohup tensorboard --logdir outdir/logs > tensorboard.out 2>&1 &


====

TRAIN FROM A CHECKPOINT

python train.py -c config.json -p train_config.ignore_layers=["speaker_embedding.weight"] train_config.checkpoint_path="models/flowtron_ljs.pt"

====

INFERENCE

1) Download waveglow_256channels_ljs_v3.pt

mkdir models
cd models
curl -LO 'https://api.ngc.nvidia.com/v2/models/nvidia/waveglow_ljs_256channels/versions/3/files/waveglow_256channels_ljs_v3.pt'

2) Copy the checkpoint to models folder

cp outdir/model_1000 models/flowtron_lada.pt

3) Run it

python inference.py --eng 0 -c config.json -f models/flowtron_lada.pt -w models/waveglow_256channels_ljs_v3.pt -t "Добрий день!" -i 0

---

Inference using English model:

1) Install gdown

    pip install gdown

2) Download flowtron_ljs.pt

    cd models
    ~/.local/bin/gdown --fuzzy "https://drive.google.com/file/d/1Cjd6dK_eFz6DE0PKXKgKxrzTUqzzUDW-/view"

3) Do inference 

    python3 inference.py -c config.json -f models/flowtron_ljs.pt -w models/waveglow_256channels_ljs_v3.pt -t "You initialise a random tenor at the start of" -i 0

Results are in the results folder
